{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from sklearn.tree import export_graphviz\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier as xgbclass\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, precision_score, recall_score, f1_score,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "root_path = \"../../Data/GoogleDrive/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel computing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores available: 8\n",
      "Number of threads set to: 6\n"
     ]
    }
   ],
   "source": [
    "# Get the number of available CPU cores\n",
    "num_cores = os.cpu_count()\n",
    "\n",
    "print(\"Number of CPU cores available:\", num_cores)\n",
    "\n",
    "# Set number of cores\n",
    "threads = os.cpu_count() - 2\n",
    "\n",
    "print(\"Number of threads set to:\", threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet(root_path + \"X_train.parquet\")\n",
    "X_test = pd.read_parquet(root_path + \"X_test.parquet\")\n",
    "y_train = pd.read_parquet(root_path + \"y_train.parquet\")\n",
    "y_test = pd.read_parquet(root_path + \"y_test.parquet\")\n",
    "data_id = \"full\" # For determining if full or selected dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting target to 1D array for sklearn Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backward selection for logistic regression\n",
    "Uncomment to run backwards selection. Takes about 3 hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SequentialFeatureSelector\n",
    "# b_logi = LogisticRegression(max_iter = 300,\n",
    "#                             solver = 'liblinear')\n",
    "# back_selector = SequentialFeatureSelector(b_logi, direction = 'backward', \n",
    "#                                           scoring = 'f1')\n",
    "# back_selector.fit(X_train, y_train)\n",
    "\n",
    "# print(back_selector.k_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the selection model\n",
    "# with open(root_path + 'back_selection.pkl', 'wb') as file:\n",
    "#     pickle.dump(back_selector, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To use the backward selected features, uncomment tthe following code chunk\n",
    "- and use X_train_selected and X_test_selected for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_path + \"back_selection.pkl\", \"rb\") as file:\n",
    "    back_selector = pickle.load(file)\n",
    "\n",
    "# Get the selected feature names\n",
    "selected_features = back_selector.get_feature_names_out()\n",
    "# Filter the feature names based on the selected features\n",
    "#selected_feature_names = X_train.columns[selected_features]\n",
    "\n",
    "# Naming Dataframes\n",
    "data_id = \"select\"\n",
    "\n",
    "# Transform the training and testing data using the selected feature names\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wtmartinez/anaconda3/envs/203C/lib/python3.11/site-packages/sklearn/metrics/_scorer.py:548: FutureWarning: The `needs_threshold` and `needs_proba` parameter are deprecated in version 1.4 and will be removed in 1.6. You can either let `response_method` be `None` or set it to `predict` to preserve the same behaviour.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__C': 0.01, 'clf__class_weight': 'balanced', 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best cross-validation ROC AUC score: 0.84\n"
     ]
    }
   ],
   "source": [
    "roc_auc_scorer = make_scorer(roc_auc_score,\n",
    "                             needs_threshold = True,\n",
    "                             multi_class = 'ovo')\n",
    "\n",
    "# define a tuning grid for logistic regression\n",
    "logi_grid = {\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__solver': ['liblinear', 'saga'],\n",
    "    'clf__class_weight': [None, 'balanced'],\n",
    "}\n",
    "\n",
    "\n",
    "# define a logistic regression model\n",
    "log_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(max_iter = 1000))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state = 69)\n",
    "\n",
    "# define a grid search with cross-validation\n",
    "log_grid_search = GridSearchCV(estimator = log_pipe,\n",
    "                               param_grid = logi_grid,\n",
    "                               cv = cv,\n",
    "                               scoring = roc_auc_scorer,\n",
    "                               n_jobs = threads,\n",
    "                               verbose = 0)\n",
    "\n",
    "# fit the grid search\n",
    "log_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the best parameters\n",
    "print(\"Best parameters:\", log_grid_search.best_params_)\n",
    "print(\"Best cross-validation ROC AUC score: {:.2f}\".format(log_grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the training data with the best logistic regression model\n",
    "log_final = log_grid_search.best_estimator_\n",
    "\n",
    "y_pred_test_logi = log_final.predict(X_test)\n",
    "y_pred_prob_logi = log_final.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_path + f\"logit_model_{data_id}.pkl\", 'wb') as file:\n",
    "    pickle.dump(log_grid_search, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'knn__metric': 'manhattan', 'knn__n_neighbors': 30, 'knn__weights': 'distance'}\n",
      "Best cross-validation score: 0.81\n"
     ]
    }
   ],
   "source": [
    "knn_param_grid = {\n",
    "    'knn__n_neighbors': np.arange(20,41,2),\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state = 69)\n",
    "\n",
    "knn_grid_search = GridSearchCV(knn_pipe,\n",
    "                               knn_param_grid,\n",
    "                               cv = cv,\n",
    "                               verbose = 0,\n",
    "                               scoring = roc_auc_scorer,\n",
    "                               n_jobs = threads)\n",
    "\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", knn_grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(knn_grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = knn_grid_search.best_estimator_\n",
    "y_pred_test_knn = best_knn.predict(X_test)\n",
    "y_pred_prob_knn = best_knn.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_path + f\"knn_model_{data_id}.pkl\", 'wb') as file:\n",
    "    pickle.dump(knn_grid_search, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wtmartinez/anaconda3/envs/203C/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=69)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 600, 1000],\n",
    "    'max_depth': [10, 20, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           scoring='accuracy', \n",
    "                           n_jobs=threads) # Parallel\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_rf_params = grid_search.best_params_\n",
    "best_rf_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_rf_params)\n",
    "print(\"Best Score:\", best_rf_score)\n",
    "\n",
    "# Use the best model to make predictions on the testing data\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "rf_predictions = best_rf_classifier.predict(X_test)\n",
    "rf_predcitions_prob = best_rf_classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "with open(root_path + f\"rf_model_{data_id}.pkl\", 'wb') as file:\n",
    "    pickle.dump(grid_search, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    # 'n_estimators':stats.randint(50, 200)\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(xgb_model, \n",
    "                           param_grid, \n",
    "                           cv=5, \n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=threads)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best set of hyperparameters and the corresponding score\n",
    "xgb_best_params = grid_search.best_params_\n",
    "xgb_best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", xgb_best_params)\n",
    "print(\"Best score: \", xgb_best_score)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model to make predictions on the testing data\n",
    "xgb_predictions = best_xgb_model.predict(X_test)\n",
    "xgb_predictions_prob = best_xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "with open(root_path + f\"xgboost_model_{data_id}.pkl\", 'wb') as file:\n",
    "    pickle.dump(grid_search, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames of Model Prediction and Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dictionary to store best models\n",
    "# best_models = {\n",
    "#     'Random Forest': best_rf_classifier,\n",
    "#     'XGBoost': best_xgb_model\n",
    "# }\n",
    "\n",
    "# # Dictionary to store predictions\n",
    "# predictions = {\n",
    "#     'Random Forest': rf_predictions,\n",
    "#     'XGBoost': xgb_predictions\n",
    "# }\n",
    "\n",
    "\n",
    "# Save the best models and predictions\n",
    "# pickle.dump(best_models, open(root_path + 'best_models.pkl', 'wb'))\n",
    "# pickle.dump(predictions, open(root_path + 'predictions.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicted values to a parquet file\n",
    "out_dir = '../../Data/GoogleDrive/'\n",
    "out_file = out_dir + 'full_test_predicted.parquet'\n",
    "\n",
    "test_predicted = pd.DataFrame({'logi_predicted': y_pred_test_logi,\n",
    "                               'logi_predicted_prob': y_pred_prob_logi,\n",
    "                               'knn_predicted': y_pred_test_knn,\n",
    "                               'knn_predicted_prob': y_pred_prob_knn,\n",
    "                               'rf_predicted': rf_predictions,\n",
    "                               'rf_predicted_prob': rf_predcitions_prob,\n",
    "                               'xgb_predicted': xgb_predictions,\n",
    "                               'xgb_predicted_prob': xgb_predictions_prob\n",
    "                               })\n",
    "\n",
    "test_predicted.to_parquet(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
