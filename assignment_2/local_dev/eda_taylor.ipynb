{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignement 2: Exploritory Data Analysis\n",
    "\n",
    "William \"Taylor\" Martinez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes and Setup\n",
    "\n",
    "[`dplyr` to `polars`](https://docs.pola.rs/user-guide/migration/pandas/#column-assignment):\n",
    "| Operation                | Syntax                                   |\n",
    "|--------------------------|------------------------------------------|\n",
    "| read (lazy)              | `df.scan_csv()` or `df.scan_parquet()`  |\n",
    "| collect                  | `df.collect()`                           |\n",
    "| select                   | `df.select(\"col_name1\", \"col_name2\")`   |\n",
    "| filter                   | `df.filter(pl.col(\"col_name\") < 10)`    |\n",
    "| mutate                   | `df.with_columns(new_col_name = pl.col(\"col_name\") * 10)` |\n",
    "| mutate (conditional)   | ```df.with_columns( pl.when(pl.col(\"c\") == 2) .then(pl.col(\"b\")) .otherwise(pl.col(\"a\")).alias(\"a\") )``` |\n",
    "| missing                  | `null`                                   |\n",
    "| all columns               | `pl.all()`                                  |\n",
    "\n",
    "`csv` vs `parquet`:\n",
    "    Parquet was chosen over `csv` because it takes up less space, it is columnar formatted, and is has improved query performance. [medium](https://medium.com/@dinesh1.chopra/unveiling-the-battle-apache-parquet-vs-csv-exploring-the-pros-and-cons-of-data-formats-b6bfd8e43107)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to parquet and read in the data\n",
    "data_path = \"../../Data/\"\n",
    "df = pl.scan_csv(data_path + \"heart_2022_with_nans.csv\")\n",
    "df.collect().write_parquet(data_path + \"heart_2022_with_nans.parquet\")\n",
    "df = pl.scan_parquet(data_path + \"heart_2022_with_nans.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Task 1: Create `HadHeartDisease` column\n",
    "\n",
    "1. Set `HadHeartDisease` to `True` if the survey participant reported having a least one of the following adverse cardiovascular events: heart attack (`HadHeartAttack`), stroke (`HadStroke`), or angina  (`HadAngina`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 41)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>State</th><th>Sex</th><th>GeneralHealth</th><th>PhysicalHealthDays</th><th>MentalHealthDays</th><th>LastCheckupTime</th><th>PhysicalActivities</th><th>SleepHours</th><th>RemovedTeeth</th><th>HadHeartAttack</th><th>HadAngina</th><th>HadStroke</th><th>HadAsthma</th><th>HadSkinCancer</th><th>HadCOPD</th><th>HadDepressiveDisorder</th><th>HadKidneyDisease</th><th>HadArthritis</th><th>HadDiabetes</th><th>DeafOrHardOfHearing</th><th>BlindOrVisionDifficulty</th><th>DifficultyConcentrating</th><th>DifficultyWalking</th><th>DifficultyDressingBathing</th><th>DifficultyErrands</th><th>SmokerStatus</th><th>ECigaretteUsage</th><th>ChestScan</th><th>RaceEthnicityCategory</th><th>AgeCategory</th><th>HeightInMeters</th><th>WeightInKilograms</th><th>BMI</th><th>AlcoholDrinkers</th><th>HIVTesting</th><th>FluVaxLast12</th><th>PneumoVaxEver</th><th>TetanusLast10Tdap</th><th>HighRiskLastYear</th><th>CovidPos</th><th>HadHeartDisease</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Alabama&quot;</td><td>&quot;Female&quot;</td><td>&quot;Very good&quot;</td><td>0.0</td><td>0.0</td><td>&quot;Within past ye…</td><td>&quot;No&quot;</td><td>8.0</td><td>null</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Never smoked&quot;</td><td>&quot;Not at all (ri…</td><td>&quot;No&quot;</td><td>&quot;White only, No…</td><td>&quot;Age 80 or olde…</td><td>null</td><td>null</td><td>null</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes, received …</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td></tr><tr><td>&quot;Alabama&quot;</td><td>&quot;Female&quot;</td><td>&quot;Excellent&quot;</td><td>0.0</td><td>0.0</td><td>null</td><td>&quot;No&quot;</td><td>6.0</td><td>null</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Never smoked&quot;</td><td>&quot;Never used e-c…</td><td>&quot;No&quot;</td><td>&quot;White only, No…</td><td>&quot;Age 80 or olde…</td><td>1.6</td><td>68.04</td><td>26.57</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No, did not re…</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td></tr><tr><td>&quot;Alabama&quot;</td><td>&quot;Female&quot;</td><td>&quot;Very good&quot;</td><td>2.0</td><td>3.0</td><td>&quot;Within past ye…</td><td>&quot;Yes&quot;</td><td>5.0</td><td>null</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Never smoked&quot;</td><td>&quot;Never used e-c…</td><td>&quot;No&quot;</td><td>&quot;White only, No…</td><td>&quot;Age 55 to 59&quot;</td><td>1.57</td><td>63.5</td><td>25.61</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>null</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td></tr><tr><td>&quot;Alabama&quot;</td><td>&quot;Female&quot;</td><td>&quot;Excellent&quot;</td><td>0.0</td><td>0.0</td><td>&quot;Within past ye…</td><td>&quot;Yes&quot;</td><td>7.0</td><td>null</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Current smoker…</td><td>&quot;Never used e-c…</td><td>&quot;Yes&quot;</td><td>&quot;White only, No…</td><td>null</td><td>1.65</td><td>63.5</td><td>23.3</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No, did not re…</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td></tr><tr><td>&quot;Alabama&quot;</td><td>&quot;Female&quot;</td><td>&quot;Fair&quot;</td><td>2.0</td><td>0.0</td><td>&quot;Within past ye…</td><td>&quot;Yes&quot;</td><td>9.0</td><td>null</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Never smoked&quot;</td><td>&quot;Never used e-c…</td><td>&quot;Yes&quot;</td><td>&quot;White only, No…</td><td>&quot;Age 40 to 44&quot;</td><td>1.57</td><td>53.98</td><td>21.77</td><td>&quot;Yes&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;Yes&quot;</td><td>&quot;No, did not re…</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td><td>&quot;No&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 41)\n",
       "┌─────────┬────────┬────────────┬────────────┬───┬────────────┬────────────┬──────────┬────────────┐\n",
       "│ State   ┆ Sex    ┆ GeneralHea ┆ PhysicalHe ┆ … ┆ TetanusLas ┆ HighRiskLa ┆ CovidPos ┆ HadHeartDi │\n",
       "│ ---     ┆ ---    ┆ lth        ┆ althDays   ┆   ┆ t10Tdap    ┆ stYear     ┆ ---      ┆ sease      │\n",
       "│ str     ┆ str    ┆ ---        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ str      ┆ ---        │\n",
       "│         ┆        ┆ str        ┆ f64        ┆   ┆ str        ┆ str        ┆          ┆ str        │\n",
       "╞═════════╪════════╪════════════╪════════════╪═══╪════════════╪════════════╪══════════╪════════════╡\n",
       "│ Alabama ┆ Female ┆ Very good  ┆ 0.0        ┆ … ┆ Yes,       ┆ No         ┆ No       ┆ No         │\n",
       "│         ┆        ┆            ┆            ┆   ┆ received   ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ tetanus    ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ shot but   ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ n…         ┆            ┆          ┆            │\n",
       "│ Alabama ┆ Female ┆ Excellent  ┆ 0.0        ┆ … ┆ No, did    ┆ No         ┆ No       ┆ No         │\n",
       "│         ┆        ┆            ┆            ┆   ┆ not        ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ receive    ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ any        ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ tetanus …  ┆            ┆          ┆            │\n",
       "│ Alabama ┆ Female ┆ Very good  ┆ 2.0        ┆ … ┆ null       ┆ No         ┆ Yes      ┆ No         │\n",
       "│ Alabama ┆ Female ┆ Excellent  ┆ 0.0        ┆ … ┆ No, did    ┆ No         ┆ No       ┆ No         │\n",
       "│         ┆        ┆            ┆            ┆   ┆ not        ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ receive    ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ any        ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ tetanus …  ┆            ┆          ┆            │\n",
       "│ Alabama ┆ Female ┆ Fair       ┆ 2.0        ┆ … ┆ No, did    ┆ No         ┆ No       ┆ No         │\n",
       "│         ┆        ┆            ┆            ┆   ┆ not        ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ receive    ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ any        ┆            ┆          ┆            │\n",
       "│         ┆        ┆            ┆            ┆   ┆ tetanus …  ┆            ┆          ┆            │\n",
       "└─────────┴────────┴────────────┴────────────┴───┴────────────┴────────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create HadHeartDisease Column\n",
    "# Conditional mutate\n",
    "df = df.with_columns(\n",
    "    pl.when(\n",
    "        (pl.col(\"HadHeartAttack\") == \"Yes\") |\n",
    "        (pl.col(\"HadStroke\") == \"Yes\") |\n",
    "        (pl.col(\"HadAngina\") == \"Yes\")\n",
    "    )\n",
    "    .then(pl.lit(\"Yes\"))\n",
    "    .otherwise(pl.lit(\"No\"))\n",
    "    .alias(\"HadHeartDisease\")\n",
    ")\n",
    "\n",
    "df.fetch(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Task 2: Drop Observations With Too Many Missing Values\n",
    "\n",
    "1. Create `df_heart_drop` where participants are dropped if Heart attack (`HadHeartAttack`), stroke (`HadStroke`), or angina  (`HadAngina`) are missing.\n",
    "\n",
    "2. From `df_heart_drop`, make multiple dataframes that drop survey participants based\n",
    "on the number of missing responses.\n",
    "\n",
    "3. Collect the dataframes and return the length of each entry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_heart_drop_00: 246022\n",
      "df_heart_drop_01: 331181\n",
      "df_heart_drop_03: 381718\n",
      "df_heart_drop_05: 391725\n",
      "df_heart_drop_10: 410245\n",
      "df_heart_drop_20: 436507\n",
      "df_heart_drop_40: 437510\n"
     ]
    }
   ],
   "source": [
    "### Automatically drop observations where HadHeartAttack, HadStroke, and HadAngina are missing.\n",
    "df_heart_drop = df.drop_nulls(subset=[\"HadHeartAttack\", \"HadStroke\", \"HadAngina\"])\n",
    "\n",
    "### Drop Observations Based On Number Of Missing Values\n",
    "thresholds = [0, 1, 3, 5, 10, 20, 40] # if number of missing is > threshold, drop the observation.\n",
    "for threshold in thresholds:\n",
    "    df_name = f\"df_heart_drop_{threshold:02}\" \n",
    "    # Drop if the row sum of all columns where the value is null is greater than threshold\n",
    "    globals()[df_name] = df_heart_drop.filter(pl.sum_horizontal(pl.all().is_null()) <= threshold)\n",
    "    # Print the number of rows in each dataframe.\n",
    "    print(df_name + \": \" + str(globals()[df_name].select(pl.len()).collect().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Task 3: Impute remaining missing values\n",
    "\n",
    "1. Show column types\n",
    "\n",
    "2. Impute float and integer values by median.\n",
    "\n",
    "3. Impute string values by mode.\n",
    "\n",
    "Note: This is applied to df_heart_drop, other dataframes can be imputed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unique data types:\n",
    "# print(set(df_heart_drop.dtypes))\n",
    "\n",
    "### Imputation\n",
    "def impute_df(df):\n",
    "    df = df.collect() # Collect because iteration is needed.\n",
    "    for i in range(len(df.columns)):\n",
    "        col_name = df.columns[i]\n",
    "        dtype = df.dtypes[i]\n",
    "        ## Impute string using the mode\n",
    "        if dtype == pl.Utf8:\n",
    "            mode_value = df[col_name].mode()\n",
    "            df = df.with_columns(df[col_name].fill_null(mode_value))\n",
    "        ## Impute float using the median\n",
    "        elif dtype == pl.Float64:\n",
    "            median_value = df[col_name].median()\n",
    "            df = df.with_columns(df[col_name].fill_null(median_value))\n",
    "        ## Warning catch: if type is not a string or float.\n",
    "        else:\n",
    "            print(\"Unexpected type:\", dtype)\n",
    "    return df\n",
    "\n",
    "### Show the number of missing values for each column\n",
    "# impute_df(df_heart_drop).null_count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Task 4: Show tables/graphs representing each task\n",
    "\n",
    "1. Table comparing the number of observations of `HadHeartAttack`, `HadStroke`, `HadAngina` and the summarized column `HadHeartDisease`.\n",
    "    a. Provide an example using a rudimentary model (Logit Regression with enet regularization)\n",
    "\n",
    "2. Table showing the number of observations after setting a missing threshold.\n",
    "    a. Provide an example using a rudimentary model (Logit Regression with enet regularization)\n",
    "\n",
    "3. Table comparing using imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "203C",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
