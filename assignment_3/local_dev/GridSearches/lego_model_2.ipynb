{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lego Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # List \n",
    "import time # Runtime\n",
    "import pickle # Model Saving\n",
    "import logging # Log Checkpoints\n",
    "import numpy as np # Flatten y vectors\n",
    "import pandas as pd # DataFrame\n",
    "import polars as pl # LazyFrame\n",
    "from sklearn.preprocessing import StandardScaler # X Standardization\n",
    "from sklearn.neural_network import MLPClassifier as mlp # model\n",
    "from sklearn.metrics import recall_score, roc_auc_score, accuracy_score, auc, roc_curve  # Scoring\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, ParameterGrid\n",
    "from great_tables import GT, md, html, from_column, style, loc, vals\n",
    "from assignment_3_tools import parquet_to_dict, unq_df_names, corr_testset\n",
    "import xgboost as xgb\n",
    "# add scikit optimize for bayesian optimization\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_gridsearch(lazy_dict, unq_names, param_grid, save_pth, test_name, threads=None):\n",
    "    \"\"\"\n",
    "    MLP GridSearch using 5-fold Cross Validation. Saves best model and results.\n",
    "    ---\n",
    "    Args:\n",
    "        lazy_dict: Dictionary with names and LazyFrames of train and test sets.\n",
    "        unq_names: List of unique names of parent datasets.\n",
    "        param_grid: Dictionary of parameters for MLPClassifier. CHANGE FOR BAESIAN\n",
    "        save_pth: String of the path to save the best model.\n",
    "        test_name: String of the test performed. PARAMETER BEING TESTED\n",
    "        threads: Integer of CPU threads for cross-validation (optional).\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    ## Initializing\n",
    "    # Define number of threads to be used in GridSearch\n",
    "    if threads is None:\n",
    "        threads = os.cpu_count() - 4\n",
    "        print(f\"Using {threads} CPU threads!\")\n",
    "\n",
    "    # Log for debugging\n",
    "    logging.basicConfig(\n",
    "        filename=f\"./log/MLP_{test_name}.log\",\n",
    "        filemode='w', \n",
    "        level=logging.INFO, \n",
    "        format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    ## GridSearch and Results\n",
    "    for name in unq_names:\n",
    "        # Results from prediction on test_set. FOR TEST TABLE\n",
    "        best_results = {\n",
    "            \"Dataset_Name\": [],\n",
    "            \"Grid_Variable\": [],\n",
    "            \"Parameters\": [],\n",
    "            \"Recall\": [], \n",
    "            \"ROC_AUC\": [], \n",
    "            \"Accuracy\": [],\n",
    "            \"Fit_Time\": []}\n",
    "        \n",
    "        # Results from prediction on Cross Validation Set. FOR CV TABLE\n",
    "        param_results = {\n",
    "            \"Dataset_Name\": [],\n",
    "            \"Grid_Variable\": [],\n",
    "            \"Parameters\": [],\n",
    "            \"Recall\": [], \n",
    "            \"Fit_Time\": []}\n",
    "        \n",
    "        ## Reading and Preparing Data\n",
    "        # Dataset names in path\n",
    "        X_train_name = f\"{name}_X_train\"\n",
    "        y_train_name = f\"{name}_y_train\"\n",
    "        X_test_name = f\"{name}_X_test\"\n",
    "        y_test_name = f\"{name}_y_test\"\n",
    "\n",
    "        # Train and test sets.\n",
    "        X_train = lazy_dict[X_train_name].collect().to_pandas()\n",
    "        y_train = lazy_dict[y_train_name].collect().to_pandas()\n",
    "        X_test = lazy_dict[X_test_name].collect().to_pandas()\n",
    "        y_test = lazy_dict[y_test_name].collect().to_pandas()\n",
    "\n",
    "        # Drop index column\n",
    "        X_train.drop(columns=['__index_level_0__'], errors='ignore', inplace=True)\n",
    "        y_train.drop(columns=['__index_level_0__'], errors='ignore', inplace=True)\n",
    "        X_test.drop(columns=['__index_level_0__'], errors='ignore', inplace=True)\n",
    "        y_test.drop(columns=['__index_level_0__'], errors='ignore', inplace=True)\n",
    "\n",
    "        # Flatten response sets\n",
    "        y_train = y_train.to_numpy().ravel()\n",
    "        y_test = y_test.to_numpy().ravel()\n",
    "\n",
    "        # Standardize predictor sets\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        ## Defining Modeling and GridSearch. CHANGE FOR BEASIAN\n",
    "        # Define cross-validation folds\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=212)\n",
    "\n",
    "        # Define mlp model\n",
    "        mlp_model = mlp()\n",
    "\n",
    "        # Define GridSearch. CHANGE TO BEASIAN!!!\n",
    "        grid_search = GridSearchCV(\n",
    "            mlp_model, #mlp model\n",
    "            param_grid=param_grid, #parameter dictionary\n",
    "            cv=cv, # cv\n",
    "            scoring='recall', # best is by recall\n",
    "            n_jobs=threads,\n",
    "            verbose=3, \n",
    "            return_train_score=True) # For making CV table\n",
    "\n",
    "\n",
    "        ## Performing GridSearch\n",
    "        # Debugging Checkpoint\n",
    "        logging.info(f\"Processing dataset: {name}\")\n",
    "        print(f\"Training on {name}...\", flush=True)\n",
    "\n",
    "        # GridSearch Training and Results\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Debugging Checkpoint\n",
    "        print(f\"GridSearch completed\", flush=True)\n",
    "        logging.info(f\"GridSearch for {test_name} completed.\")\n",
    "\n",
    "        ## Results from GridSearch\n",
    "        # Storing Results for each parameter combination\n",
    "        for i in range(len(grid_search.cv_results_['params'])):\n",
    "            param_combination = grid_search.cv_results_['params'][i]\n",
    "            recall = grid_search.cv_results_['mean_test_score'][i]\n",
    "            fit_time = grid_search.cv_results_['mean_fit_time'][i]\n",
    "            param_results[\"Dataset_Name\"].append(name)\n",
    "            param_results[\"Grid_Variable\"].append(test_name)\n",
    "            param_results[\"Parameters\"].append(param_combination)\n",
    "            param_results[\"Recall\"].append(recall)\n",
    "            param_results[\"Fit_Time\"].append(fit_time)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        param_results_df = pd.DataFrame(param_results)\n",
    "        param_results_df = param_results_df.sort_values(by=\"Recall\", ascending=False)\n",
    "\n",
    "        # Best model by Recall on Cross Validation data\n",
    "        best_fit_time = param_results_df.iloc[0][\"Fit_Time\"]\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Metrics on test set\n",
    "        y_pred_test = best_model.predict(X_test_scaled)\n",
    "        test_recall = recall_score(y_test, y_pred_test)\n",
    "        test_roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test_scaled)[:, 1])\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "        # Save best model as pickle\n",
    "        # example: best_model_neurons-hidden_layer_sizes.pkl\n",
    "        with open(f\"{save_pth}best_model{test_name}-{name}.pkl\", 'wb') as file:\n",
    "            pickle.dump(best_model, file)\n",
    "\n",
    "        # Debugging Checkpoint\n",
    "        logging.info(f\"Model saved to {save_pth}\")\n",
    "\n",
    "        # Results from predicting test data using the best model.\n",
    "        best_results[\"Dataset_Name\"].append(name)\n",
    "        best_results[\"Grid_Variable\"].append(test_name)\n",
    "        best_results[\"Parameters\"].append(grid_search.best_params_)\n",
    "        best_results[\"Recall\"].append(test_recall)\n",
    "        best_results[\"ROC_AUC\"].append(test_roc_auc)\n",
    "        best_results[\"Accuracy\"].append(test_accuracy)\n",
    "        best_results[\"Fit_Time\"].append(best_fit_time)\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        best_results_df = pd.DataFrame(best_results)\n",
    "        \n",
    "        # Save results as Parquet\n",
    "        # example: test_results_layers-hidden_layer_sizes.parquet\n",
    "        best_results_df.to_parquet(f\"{save_pth}test_results{test_name}-{name}.parquet\", index=False)\n",
    "        # example: grid_results_neurons-hidden_layer_sizes.parquet\n",
    "        param_results_df.to_parquet(f\"{save_pth}grid_results{test_name}-{name}.parquet\", index=False)\n",
    "\n",
    "        # Debugging Checkpoint\n",
    "        print(f\"{test_name} GridSearch completed!\", flush=True)\n",
    "        logging.info(f\"{test_name} GridSearch completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test sets are in MLP_Dataset.\n",
    "# Save results and best model to MLP_Results.\n",
    "data_pth = \"../../../Data/GoogleDrive/MLP_Dataset/\"\n",
    "save_pth = \"../../../Data/GoogleDrive/MLP_Results/\"\n",
    "\n",
    "# Read in Parquet files in path and add to a LazyFrame dictionary.\n",
    "pq_jar = parquet_to_dict(data_pth) # all lazy\n",
    "\n",
    "# Record the unique dataset names (drop X_train, etc.).\n",
    "unq_names = unq_df_names(pq_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary of parmeter dictionaries\n",
    "# Schema {testname:{parameter:values}}\n",
    "\n",
    "two_param = {\n",
    "    '_lego_2':{\n",
    "        'solver': ['adam'],              # Solver for weight optimization\n",
    "        'hidden_layer_sizes': [(47, 46, 46, 46)]  # Number of neurons and layers, represented as a tupl\n",
    "    }\n",
    "}\n",
    "\n",
    "test_2 = '_best_lego_2'\n",
    "test = test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 CPU threads!\n",
      "Training on Under_Sample_1:1_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.932, test=0.912) total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.943, test=0.922) total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.932, test=0.917) total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.938, test=0.919) total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.940, test=0.922) total time= 5.8min\n",
      "GridSearch completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_lego_2 GridSearch completed!\n",
      "CPU times: user 4h 48min 41s, sys: 9min 34s, total: 4h 58min 15s\n",
      "Wall time: 32min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the model\n",
    "for test, param_dict in two_param.items():\n",
    "    mlp_gridsearch(pq_jar, unq_names, param_dict, save_pth, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_param = {\n",
    "    '_best_lego_3_2': {\n",
    "        'solver': ['adam'],               # Solver for weight optimization\n",
    "        'hidden_layer_sizes': [(47, 46, 46, 46)],  # Number of neurons and layers, represented as a tuple\n",
    "        'activation': ['logistic'],           # Activation function\n",
    "    }\n",
    "}\n",
    "test_3 = '_best_lego_3_2'\n",
    "test = test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 CPU threads!\n",
      "Training on Under_Sample_1:1_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.955, test=0.947) total time= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.945, test=0.935) total time= 6.5min\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.950, test=0.940) total time= 6.5min\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.940, test=0.929) total time= 6.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), solver=adam;, score=(train=0.940, test=0.929) total time= 6.5min\n",
      "GridSearch completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_best_lego_3_2 GridSearch completed!\n",
      "CPU times: user 4h 3min 51s, sys: 7min 15s, total: 4h 11min 6s\n",
      "Wall time: 28min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the model\n",
    "for test, param_dict in three_param.items():\n",
    "    mlp_gridsearch(pq_jar, unq_names, param_dict, save_pth, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_param = {\n",
    "    '_best_lego_4_2': {\n",
    "        'solver': ['adam'],               # Solver for weight optimization\n",
    "        'hidden_layer_sizes': [(47, 46, 46, 46)],  # Number of neurons and layers, represented as a tuple\n",
    "        'activation': ['logistic'],           # Activation function\n",
    "        'learning_rate_init': [0.01],     # Initial learning rate\n",
    "    }\n",
    "}\n",
    "test_4 = '_best_lego_4_2'\n",
    "test = test_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 CPU threads!\n",
      "Training on Under_Sample_1:1_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, solver=adam;, score=(train=0.939, test=0.926) total time= 2.3min\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, solver=adam;, score=(train=0.943, test=0.930) total time= 2.5min\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, solver=adam;, score=(train=0.933, test=0.920) total time= 2.5min\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, solver=adam;, score=(train=0.890, test=0.876) total time= 2.6min\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, solver=adam;, score=(train=0.947, test=0.936) total time= 2.7min\n",
      "GridSearch completed\n",
      "_best_lego_4_2 GridSearch completed!\n",
      "CPU times: user 1h 4min 41s, sys: 1min 55s, total: 1h 6min 36s\n",
      "Wall time: 8min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the model\n",
    "for test, param_dict in four_param.items():\n",
    "    mlp_gridsearch(pq_jar, unq_names, param_dict, save_pth, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_param = {\n",
    "    '_best_lego_5_2': {\n",
    "        'solver': ['adam'],               # Solver for weight optimization\n",
    "        'hidden_layer_sizes': [(47, 46, 46, 46)],  # Number of neurons and layers, represented as a tuple\n",
    "        'activation': ['logistic'],           # Activation function\n",
    "        'learning_rate_init': [0.01],     # Initial learning rate\n",
    "        'max_iter': [100],                # Maximum number of iterations\n",
    "    }\n",
    "}\n",
    "test_5 = '_best_lego_5_2'\n",
    "test = test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 CPU threads!\n",
      "Training on Under_Sample_1:1_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, solver=adam;, score=(train=0.922, test=0.908) total time= 2.0min\n",
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, solver=adam;, score=(train=0.878, test=0.866) total time= 2.2min\n",
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, solver=adam;, score=(train=0.907, test=0.892) total time= 2.4min\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, solver=adam;, score=(train=0.937, test=0.923) total time= 2.4min\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, solver=adam;, score=(train=0.901, test=0.884) total time= 2.4min\n",
      "GridSearch completed\n",
      "_best_lego_5_2 GridSearch completed!\n",
      "CPU times: user 1h 10min 59s, sys: 2min 25s, total: 1h 13min 25s\n",
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the model\n",
    "for test, param_dict in five_param.items():\n",
    "    mlp_gridsearch(pq_jar, unq_names, param_dict, save_pth, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_param = {\n",
    "    '_best_lego_6_2': {\n",
    "        'solver': ['adam'],               # Solver for weight optimization\n",
    "        'hidden_layer_sizes': [(47, 46, 46, 46)],  # Number of neurons and layers, represented as a tuple\n",
    "        'activation': ['logistic'],           # Activation function\n",
    "        'learning_rate_init': [0.01],     # Initial learning rate\n",
    "        'max_iter': [100],                # Maximum number of iterations\n",
    "        'n_iter_no_change': [100],         # Number of iterations with no improvement to stop training\n",
    "    }\n",
    "}\n",
    "test_6 = '_best_lego_6_2'\n",
    "test = test_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 CPU threads!\n",
      "Training on Under_Sample_1:1_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.917, test=0.902) total time= 3.1min\n",
      "[CV 5/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.893, test=0.877) total time= 3.1min\n",
      "[CV 1/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.949, test=0.935) total time= 3.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.901, test=0.887) total time= 3.1min\n",
      "[CV 4/5] END activation=logistic, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.913, test=0.900) total time= 3.1min\n",
      "GridSearch completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_best_lego_6_2 GridSearch completed!\n",
      "CPU times: user 1h 59min 56s, sys: 4min 7s, total: 2h 4min 4s\n",
      "Wall time: 13min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the model\n",
    "for test, param_dict in six_param.items():\n",
    "    mlp_gridsearch(pq_jar, unq_names, param_dict, save_pth, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_param = {\n",
    "    '_best_lego_7_3': {\n",
    "        'solver': ['adam'],               # Solver for weight optimization\n",
    "        'hidden_layer_sizes': [(47, 46, 46, 46)],  # Number of neurons and layers, represented as a tuple\n",
    "        'activation': ['logistic'],           # Activation function\n",
    "        'learning_rate_init': [0.01],     # Initial learning rate\n",
    "        'max_iter': [100],                # Maximum number of iterations\n",
    "        'n_iter_no_change': [100],         # Number of iterations with no improvement to stop training\n",
    "        'batch_size': [100],           # Size of minibatches\n",
    "    }\n",
    "}\n",
    "test_7 = '_best_lego_7_3'\n",
    "test = test_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 CPU threads!\n",
      "Training on Under_Sample_1:1_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=logistic, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.905, test=0.897) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.899, test=0.887) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=logistic, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.918, test=0.906) total time= 3.7min\n",
      "[CV 3/5] END activation=logistic, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.882, test=0.868) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=logistic, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.912, test=0.899) total time= 3.8min\n",
      "GridSearch completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_best_lego_7_3 GridSearch completed!\n",
      "CPU times: user 1h 37min 2s, sys: 1min 57s, total: 1h 38min 59s\n",
      "Wall time: 12min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the model\n",
    "for test, param_dict in seven_param.items():\n",
    "    mlp_gridsearch(pq_jar, unq_names, param_dict, save_pth, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_param = {\n",
    "    '_best_lego_8_3': {\n",
    "        'solver': ['adam'],               # Solver for weight optimization\n",
    "        'hidden_layer_sizes': [(47, 46, 46, 46)],  # Number of neurons and layers, represented as a tuple\n",
    "        'activation': ['logistic'],           # Activation function\n",
    "        'learning_rate_init': [0.01],     # Initial learning rate\n",
    "        'max_iter': [100],                # Maximum number of iterations\n",
    "        'n_iter_no_change': [100],         # Number of iterations with no improvement to stop training\n",
    "        'batch_size': [100],           # Size of minibatches\n",
    "        'alpha': [0.0]                 # Regularization parameter\n",
    "    }\n",
    "}\n",
    "test_8 = '_best_lego_8_3'\n",
    "test = test_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 8 CPU threads!\n",
      "Training on Under_Sample_1:1_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END activation=logistic, alpha=0.0, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.903, test=0.886) total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=logistic, alpha=0.0, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.915, test=0.903) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END activation=logistic, alpha=0.0, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.853, test=0.840) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END activation=logistic, alpha=0.0, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.887, test=0.877) total time= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END activation=logistic, alpha=0.0, batch_size=100, hidden_layer_sizes=(47, 46, 46, 46), learning_rate_init=0.01, max_iter=100, n_iter_no_change=100, solver=adam;, score=(train=0.895, test=0.885) total time= 3.9min\n",
      "GridSearch completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_best_lego_8_3 GridSearch completed!\n",
      "CPU times: user 1h 34min 19s, sys: 1min 55s, total: 1h 36min 14s\n",
      "Wall time: 12min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run the model\n",
    "for test, param_dict in eight_param.items():\n",
    "    mlp_gridsearch(pq_jar, unq_names, param_dict, save_pth, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
