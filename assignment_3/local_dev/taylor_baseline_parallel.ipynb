{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172a3989-77d6-45cd-92eb-e253edc380d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import logging\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import recall_score, roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from assignment_3_tools import parquet_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e25607-35c5-461d-95bb-4ce9f05eb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Datasets.\n",
    "def unq_df_names(lazy_dict):\n",
    "    \"\"\"\n",
    "    Creates a set of unique datasets from a LazyFrame dictionary.\n",
    "    ---\n",
    "    Args: \n",
    "        lazy_dict (dict): Contains LazyFrame names and corresponding LazyFrames.\n",
    "    Returns:\n",
    "        unq_names (set): Contains unique dataset names.\n",
    "    \"\"\"\n",
    "    all_names = list()\n",
    "    for key in lazy_dict:\n",
    "        if key[-6:] == \"_train\":\n",
    "            all_names.append(key[:-8]) # Remove _X_train and _y_train\n",
    "        elif key[-5:] == \"_test\":\n",
    "            all_names.append(key[:-7]) # Remove _X_test and _y_test\n",
    "        else:\n",
    "            pass\n",
    "    unq_names = set(all_names)\n",
    "    return unq_names\n",
    "\n",
    "# Return Corresponding Test Set.\n",
    "def corr_testset(unq_name):\n",
    "    \"\"\"\n",
    "    Return the names of testsets corresponding to a preprocessed trainset\n",
    "    ---\n",
    "    Args:\n",
    "        unq_name(set): Contains unique dataset names.\n",
    "    Returns:\n",
    "        X_test_name(str): Name of corresponding predictor testset.\n",
    "        y_test_name(str): Name of corresponding response testset.\n",
    "    \"\"\"\n",
    "    threshold = unq_name[-2:] # 2 possibilities: \"##\" or \"mp\"\n",
    "    if threshold.isnumeric():\n",
    "        # Use null-threshold datasets with no balancing operations.\n",
    "        X_test_name = f\"df_heart_drop_{threshold}_imp_X_test\"\n",
    "        y_test_name = f\"df_heart_drop_{threshold}_imp_y_test\"\n",
    "    else:\n",
    "        # Use null-threshold datasets with no balancing operations. \n",
    "        X_test_name = f\"{unq_name}_X_test\"\n",
    "        y_test_name = f\"{unq_name}_y_test\"\n",
    "    return X_test_name, y_test_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8396476-f7ff-4369-b6fd-ac268e18439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(name, lazy_dict, param_grid, save_pth):\n",
    "    X_train_name = f\"{name}_X_train\"\n",
    "    y_train_name = f\"{name}_y_train\"\n",
    "    (X_test_name, y_test_name) = corr_testset(name)\n",
    "\n",
    "    X_train = lazy_dict[X_train_name].collect().to_pandas()\n",
    "    y_train = lazy_dict[y_train_name].collect().to_pandas()\n",
    "    X_test = lazy_dict[X_test_name].collect().to_pandas()\n",
    "    y_test = lazy_dict[y_test_name].collect().to_pandas()\n",
    "\n",
    "    X_train.drop(columns=['__index_level_0__'], errors='ignore', inplace=True)\n",
    "    y_train.drop(columns=['__index_level_0__'], errors='ignore', inplace=True)\n",
    "    X_test.drop(columns=['__index_level_0__'], errors='ignore', inplace=True)\n",
    "    y_test.drop(columns=['__index_level_0__'], errors='ignore', inplace=True)\n",
    "\n",
    "    y_train = y_train.to_numpy().ravel()\n",
    "    y_test = y_test.to_numpy().ravel()\n",
    "\n",
    "    # Data scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Setup model and GridSearchCV\n",
    "    mlp_model = MLPClassifier(early_stopping=True, verbose=False, random_state=212)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=212)\n",
    "    grid_search = GridSearchCV(mlp_model, param_grid=param_grid, cv=cv, scoring='recall', verbose=1)\n",
    "    \n",
    "    \n",
    "    logging.info(f\"Processing dataset: {name}\")\n",
    "    print(f\"Training on {name}...\", flush=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    print(f\"{name}GridSearch completed\", flush=True)\n",
    "    logging.info(f\"{name}GridSearch completed.\")    \n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_pred_test = best_model.predict(X_test_scaled)\n",
    "    test_recall = recall_score(y_test, y_pred_test)\n",
    "    test_roc_auc = roc_auc_score(y_test, best_model.predict_proba(X_test_scaled)[:, 1])\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Save the model\n",
    "    with open(f\"{save_pth}{name}_MLPbaseline.pkl\", 'wb') as file:\n",
    "        pickle.dump(best_model, file)\n",
    "\n",
    "    logging.info(f\"{name}Model saved to {save_pth}\")\n",
    "\n",
    "    return {\n",
    "        \"Dataset Name\": name,\n",
    "        \"Best Recall\": test_recall,\n",
    "        \"Best ROCAUC\": test_roc_auc,\n",
    "        \"Best Accuracy\": test_accuracy,\n",
    "        \"Fit Time\": fit_time}\n",
    "\n",
    "def mlp_baseline(lazy_dict, unq_names, param_grid, save_pth, threads=None):\n",
    "    if threads is None:\n",
    "        threads = os.cpu_count() - 2  # Save some resources for other processes\n",
    "        print(f\"Using {threads} CPU threads!\")\n",
    "        \n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=threads) as executor:\n",
    "        futures = [executor.submit(process_dataset, name, lazy_dict, param_grid, save_pth) for name in unq_names]\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            logging.info(f\"Completed processing for {result['Dataset Name']}\")\n",
    "            print(f\"Completed processing for {result['Dataset Name']}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_parquet(\"../../Data/GoogleDrive/baseline_results.parquet\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd75fc-fb6f-4a82-a52f-f98bd6897c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 14 CPU threads!\n",
      "Training on df_heart_drop_05_imp...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on df_heart_drop_03_imp...\n",
      "Training on Under_Sample_1:1_threshold_00...Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Under_Sample_2:1_threshold_00...\n",
      "Training on Over_Sample_1:1_threshold_03...Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Over_Sample_1:3_threshold_00...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Over_Sample_1:2_threshold_01...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Over_Sample_1:1_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Under_Sample_3:1_threshold_01...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Over_Sample_1:2_threshold_10...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Under_Sample_3:1_threshold_40...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Under_Sample_3:1_threshold_10...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Over_Sample_1:5_threshold_20...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Training on Over_Sample_1:7_threshold_00...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wtmartinez/anaconda3/envs/203C/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Log Initialization\n",
    "logging.basicConfig(filename='./log/MLP_baseline.log', filemode='w', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "## Paths\n",
    "data_pth = \"../../Data/GoogleDrive/Encoded_Data/\"\n",
    "save_pth = \"../../Data/GoogleDrive/Baseline/\"\n",
    "\n",
    "## Read in Parquet to LazyFrame Dictionary.\n",
    "pq_jar = parquet_to_dict(data_pth)\n",
    "\n",
    "## Record the unique dataset names.\n",
    "unq_names = unq_df_names(pq_jar)\n",
    "\n",
    "## List the default sklearn mlp_classification parameters.\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,)],  # Single layer with 100 neurons\n",
    "    'activation': ['relu'],  # Using 'relu' activation function\n",
    "    'solver': ['adam'],  # Solver set to 'adam'\n",
    "    'alpha': [0.0001],  # L2 penalty (regularization term)\n",
    "    'batch_size': ['auto'],  # 'auto' sets batch size to min(200, n_samples)\n",
    "    'learning_rate': ['constant'],  # Learning rate schedule\n",
    "    'learning_rate_init': [0.001],  # Initial learning rate\n",
    "    'power_t': [0.5],  # The exponent for inverse scaling learning rate\n",
    "    'max_iter': [200],  # Maximum number of iterations\n",
    "    'shuffle': [True],  # Whether to shuffle samples in each iteration\n",
    "    'random_state': [212],  # Random state for reproducibility, can set to a specific number\n",
    "    'tol': [0.0001],  # Tolerance for the optimization\n",
    "    'verbose': [False],  # Whether to print progress messages to stdout\n",
    "    'warm_start': [False],  # Reuse solution of the previous call to fit as initialization\n",
    "    'momentum': [0.9],  # Momentum for gradient descent update\n",
    "    'nesterovs_momentum': [True],  # Whether to use Nesterov's momentum\n",
    "    'early_stopping': [True],  # Whether to use early stopping to terminate training\n",
    "    'validation_fraction': [0.1],  # Proportion of training data to set aside as validation set\n",
    "    'beta_1': [0.9],  # Exponential decay rate for estimates of first moment vector in adam\n",
    "    'beta_2': [0.999],  # Exponential decay rate for estimates of second moment vector in adam\n",
    "    'epsilon': [1e-08],  # Value for numerical stability in adam\n",
    "    'n_iter_no_change': [10],  # Maximum number of epochs to not meet improvement threshold\n",
    "    'max_fun': [15000]  # Maximum number of loss function calls\n",
    "}\n",
    "\n",
    "results = mlp_baseline(pq_jar, unq_names, param_grid, save_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f741a88-2967-49b0-bda6-3e944d473448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "203C",
   "language": "python",
   "name": "203c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
