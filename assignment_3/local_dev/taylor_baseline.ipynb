{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1238c4de-bef0-427c-a31c-17418e99f09f",
   "metadata": {},
   "source": [
    "# Baseline Multi-Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e073e2-05b2-4fc6-9574-de83ef7c7f35",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074514d8-c5dc-46e5-ac94-9efaf39acdad",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Notebook Setup](#Notebook-Setup)\n",
    "- [Read in Parquet](#Read-in-Parquet)\n",
    "- [MLP Baseline Model](#Encode-Features)\n",
    "- [Results](#Results)\n",
    "- [Save as Pickle](#Save-as_Pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53820c5-2013-433a-b156-864143ef2b64",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "\n",
    "Significant functions from [assignment_3_tools.py](./assignment_3_tools.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76cb0916-cef7-4ebd-857c-814f6db863f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #for saveing and loading trained models\n",
    "from icecream import ic # Debugging\n",
    "import numpy as np # for vector / matrix operations\n",
    "import pandas as pd # for data manipulation\n",
    "import seaborn as sns # For plots\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_curve, make_scorer, recall_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "from assignment_3_tools import parquet_to_dict\n",
    "\n",
    "data_pth = \"../../Data/GoogleDrive/Encoded_Data\"\n",
    "save_pth = \"../../Data/GoogleDrive/Baseline\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cedacb-a494-4f84-8bad-42e9e86c411e",
   "metadata": {},
   "source": [
    "## Read in Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a079661f-0efa-4a34-8b58-edf66898417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy read encoded data.\n",
    "pq_jar = parquet_to_dict(data_pth)\n",
    "\n",
    "# Unique Datasets.\n",
    "def encode_dataset(lazy_dict):\n",
    "    all_names = list()\n",
    "    for i, key in enumerate(lazy_dict):\n",
    "        if key[-6:] == \"_train\":\n",
    "            all_names.append(key[:-8])\n",
    "        elif key[-5:] == \"_test\":\n",
    "            all_names.append(key[:-7])\n",
    "        else:\n",
    "            pass\n",
    "    unq_names = set(all_names)\n",
    "    return unq_names\n",
    "\n",
    "unq_names = encode_dataset(pq_jar)\n",
    "\n",
    "# Return Corresponding Test Set.\n",
    "def corr_testset(unq_name):\n",
    "    threshold = unq_name[-2:]\n",
    "    if threshold.isnumeric():\n",
    "        X_test_name = f\"df_heart_drop_{threshold}_imp_X_test\"\n",
    "        y_test_name = f\"df_heart_drop_{threshold}_imp_y_test\"\n",
    "    else:\n",
    "        X_test_name = f\"{unq_name}_X_test\"\n",
    "        y_test_name = f\"{unq_name}_y_test\"\n",
    "    return X_test_name, y_test_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e2525-b076-4432-8f3e-0303ffab4f27",
   "metadata": {},
   "source": [
    "## MLP Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81b369f3-cf02-449e-83d4-fd022340e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint - Standardized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/203C/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1101: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.37068515\n",
      "Validation score: 0.843859\n",
      "Iteration 2, loss = 0.34300745\n",
      "Validation score: 0.845979\n",
      "Iteration 3, loss = 0.33964466\n",
      "Validation score: 0.847059\n",
      "Iteration 4, loss = 0.33804217\n",
      "Validation score: 0.847673\n",
      "Iteration 5, loss = 0.33699357\n",
      "Validation score: 0.848144\n",
      "Iteration 6, loss = 0.33620212\n",
      "Validation score: 0.848388\n",
      "Iteration 7, loss = 0.33558609\n",
      "Validation score: 0.848378\n",
      "Iteration 8, loss = 0.33509143\n",
      "Validation score: 0.848763\n",
      "Iteration 9, loss = 0.33466121\n",
      "Validation score: 0.848935\n",
      "Iteration 10, loss = 0.33431845\n",
      "Validation score: 0.848920\n",
      "Iteration 11, loss = 0.33399581\n",
      "Validation score: 0.849341\n",
      "Iteration 12, loss = 0.33374200\n",
      "Validation score: 0.849676\n",
      "Iteration 13, loss = 0.33350747\n",
      "Validation score: 0.849488\n",
      "Iteration 14, loss = 0.33330164\n",
      "Validation score: 0.849554\n",
      "Iteration 15, loss = 0.33311183\n",
      "Validation score: 0.849448\n",
      "Iteration 16, loss = 0.33293470\n",
      "Validation score: 0.849579\n",
      "Iteration 17, loss = 0.33279296\n",
      "Validation score: 0.849711\n",
      "Iteration 18, loss = 0.33265825\n",
      "Validation score: 0.850178\n",
      "Iteration 19, loss = 0.33255724\n",
      "Validation score: 0.850188\n",
      "Iteration 20, loss = 0.33244677\n",
      "Validation score: 0.849757\n",
      "Iteration 21, loss = 0.33233802\n",
      "Validation score: 0.849792\n",
      "Iteration 22, loss = 0.33224087\n",
      "Validation score: 0.849919\n",
      "Iteration 23, loss = 0.33216799\n",
      "Validation score: 0.849620\n",
      "Iteration 24, loss = 0.33208424\n",
      "Validation score: 0.849772\n",
      "Iteration 25, loss = 0.33198564\n",
      "Validation score: 0.849863\n",
      "Iteration 26, loss = 0.33193342\n",
      "Validation score: 0.849813\n",
      "Iteration 27, loss = 0.33187982\n",
      "Validation score: 0.849848\n",
      "Iteration 28, loss = 0.33179862\n",
      "Validation score: 0.849965\n",
      "Iteration 29, loss = 0.33173014\n",
      "Validation score: 0.849975\n",
      "Iteration 30, loss = 0.33166901\n",
      "Validation score: 0.849889\n",
      "Iteration 31, loss = 0.33162023\n",
      "Validation score: 0.850137\n",
      "Iteration 32, loss = 0.33156807\n",
      "Validation score: 0.850107\n",
      "Iteration 33, loss = 0.33150011\n",
      "Validation score: 0.849498\n",
      "Iteration 34, loss = 0.33144160\n",
      "Validation score: 0.849579\n",
      "Iteration 35, loss = 0.33139994\n",
      "Validation score: 0.849610\n",
      "Iteration 36, loss = 0.33135719\n",
      "Validation score: 0.849757\n",
      "Iteration 37, loss = 0.33129629\n",
      "Validation score: 0.849787\n",
      "Iteration 38, loss = 0.33125153\n",
      "Validation score: 0.849879\n",
      "Iteration 39, loss = 0.33120807\n",
      "Validation score: 0.849909\n",
      "Iteration 40, loss = 0.33116451\n",
      "Validation score: 0.849326\n",
      "Iteration 41, loss = 0.33111223\n",
      "Validation score: 0.849635\n",
      "Iteration 42, loss = 0.33107823\n",
      "Validation score: 0.849818\n",
      "Iteration 43, loss = 0.33105106\n",
      "Validation score: 0.849600\n",
      "Iteration 44, loss = 0.33099331\n",
      "Validation score: 0.850010\n",
      "Iteration 45, loss = 0.33097995\n",
      "Validation score: 0.849884\n",
      "Iteration 46, loss = 0.33092219\n",
      "Validation score: 0.849858\n",
      "Iteration 47, loss = 0.33088856\n",
      "Validation score: 0.849574\n",
      "Iteration 48, loss = 0.33087218\n",
      "Validation score: 0.849777\n",
      "Iteration 49, loss = 0.33082545\n",
      "Validation score: 0.849879\n",
      "Iteration 50, loss = 0.33080158\n",
      "Validation score: 0.850000\n",
      "Iteration 51, loss = 0.33076858\n",
      "Validation score: 0.849939\n",
      "Iteration 52, loss = 0.33073287\n",
      "Validation score: 0.849965\n",
      "Iteration 53, loss = 0.33070795\n",
      "Validation score: 0.849980\n",
      "Iteration 54, loss = 0.33066803\n",
      "Validation score: 0.849711\n",
      "Iteration 55, loss = 0.33066232\n",
      "Validation score: 0.849716\n",
      "Iteration 56, loss = 0.33062528\n",
      "Validation score: 0.849747\n",
      "Iteration 57, loss = 0.33059631\n",
      "Validation score: 0.849802\n",
      "Iteration 58, loss = 0.33056576\n",
      "Validation score: 0.849524\n",
      "Iteration 59, loss = 0.33054511\n",
      "Validation score: 0.850000\n",
      "Iteration 60, loss = 0.33052745\n",
      "Validation score: 0.849828\n",
      "Iteration 61, loss = 0.33049513\n",
      "Validation score: 0.849463\n",
      "Iteration 62, loss = 0.33047605\n",
      "Validation score: 0.849579\n",
      "Iteration 63, loss = 0.33044357\n",
      "Validation score: 0.849508\n",
      "Iteration 64, loss = 0.33043667\n",
      "Validation score: 0.849463\n",
      "Iteration 65, loss = 0.33041255\n",
      "Validation score: 0.849331\n",
      "Iteration 66, loss = 0.33039560\n",
      "Validation score: 0.849463\n",
      "Iteration 67, loss = 0.33035740\n",
      "Validation score: 0.849661\n",
      "Iteration 68, loss = 0.33035946\n",
      "Validation score: 0.849534\n",
      "Iteration 69, loss = 0.33032998\n",
      "Validation score: 0.849620\n",
      "Iteration 70, loss = 0.33033029\n",
      "Validation score: 0.849508\n",
      "Iteration 71, loss = 0.33029937\n",
      "Validation score: 0.849240\n",
      "Iteration 72, loss = 0.33026231\n",
      "Validation score: 0.849417\n",
      "Iteration 73, loss = 0.33029043\n",
      "Validation score: 0.849792\n",
      "Iteration 74, loss = 0.33024864\n",
      "Validation score: 0.849508\n",
      "Iteration 75, loss = 0.33023699\n",
      "Validation score: 0.849508\n",
      "Iteration 76, loss = 0.33022904\n",
      "Validation score: 0.849432\n",
      "Iteration 77, loss = 0.33022190\n",
      "Validation score: 0.849797\n",
      "Iteration 78, loss = 0.33020217\n",
      "Validation score: 0.849382\n",
      "Iteration 79, loss = 0.33018145\n",
      "Validation score: 0.850005\n",
      "Iteration 80, loss = 0.33016185\n",
      "Validation score: 0.849519\n",
      "Iteration 81, loss = 0.33016238\n",
      "Validation score: 0.849711\n",
      "Iteration 82, loss = 0.33014682\n",
      "Validation score: 0.849635\n",
      "Iteration 83, loss = 0.33013571\n",
      "Validation score: 0.849458\n",
      "Iteration 84, loss = 0.33013656\n",
      "Validation score: 0.849635\n",
      "Iteration 85, loss = 0.33009580\n",
      "Validation score: 0.849574\n",
      "Iteration 86, loss = 0.33010610\n",
      "Validation score: 0.849326\n",
      "Iteration 87, loss = 0.33008736\n",
      "Validation score: 0.849554\n",
      "Iteration 88, loss = 0.33006350\n",
      "Validation score: 0.849483\n",
      "Iteration 89, loss = 0.33007847\n",
      "Validation score: 0.849356\n",
      "Iteration 90, loss = 0.33005493\n",
      "Validation score: 0.849630\n",
      "Iteration 91, loss = 0.33005364\n",
      "Validation score: 0.849371\n",
      "Iteration 92, loss = 0.33003704\n",
      "Validation score: 0.849123\n",
      "Iteration 93, loss = 0.33002724\n",
      "Validation score: 0.849032\n",
      "Iteration 94, loss = 0.33001000\n",
      "Validation score: 0.849524\n",
      "Iteration 95, loss = 0.32999939\n",
      "Validation score: 0.849503\n",
      "Iteration 96, loss = 0.32999098\n",
      "Validation score: 0.849285\n",
      "Iteration 97, loss = 0.32999430\n",
      "Validation score: 0.849164\n",
      "Iteration 98, loss = 0.32998630\n",
      "Validation score: 0.849108\n",
      "Iteration 99, loss = 0.32996522\n",
      "Validation score: 0.849174\n",
      "Iteration 100, loss = 0.32995676\n",
      "Validation score: 0.849448\n",
      "Iteration 101, loss = 0.32995924\n",
      "Validation score: 0.849017\n",
      "Iteration 102, loss = 0.32995100\n",
      "Validation score: 0.849326\n",
      "Iteration 103, loss = 0.32994848\n",
      "Validation score: 0.849483\n",
      "Iteration 104, loss = 0.32993043\n",
      "Validation score: 0.849889\n",
      "Iteration 105, loss = 0.32991606\n",
      "Validation score: 0.849716\n",
      "Iteration 106, loss = 0.32990600\n",
      "Validation score: 0.849468\n",
      "Iteration 107, loss = 0.32989106\n",
      "Validation score: 0.849503\n",
      "Iteration 108, loss = 0.32990001\n",
      "Validation score: 0.849169\n",
      "Iteration 109, loss = 0.32988762\n",
      "Validation score: 0.849260\n",
      "Iteration 110, loss = 0.32987167\n",
      "Validation score: 0.849777\n",
      "Iteration 111, loss = 0.32987521\n",
      "Validation score: 0.849584\n",
      "Iteration 112, loss = 0.32986685\n",
      "Validation score: 0.849382\n",
      "Iteration 113, loss = 0.32984206\n",
      "Validation score: 0.849630\n",
      "Iteration 114, loss = 0.32984008\n",
      "Validation score: 0.849371\n",
      "Iteration 115, loss = 0.32982291\n",
      "Validation score: 0.849833\n",
      "Iteration 116, loss = 0.32983097\n",
      "Validation score: 0.849250\n",
      "Iteration 117, loss = 0.32981818\n",
      "Validation score: 0.849483\n",
      "Iteration 118, loss = 0.32980574\n",
      "Validation score: 0.849377\n",
      "Iteration 119, loss = 0.32980880\n",
      "Validation score: 0.849437\n",
      "Iteration 120, loss = 0.32979218\n",
      "Validation score: 0.849686\n",
      "Iteration 121, loss = 0.32978420\n",
      "Validation score: 0.849574\n",
      "Iteration 122, loss = 0.32978507\n",
      "Validation score: 0.849605\n",
      "Iteration 123, loss = 0.32977120\n",
      "Validation score: 0.849645\n",
      "Iteration 124, loss = 0.32977375\n",
      "Validation score: 0.849427\n",
      "Iteration 125, loss = 0.32975209\n",
      "Validation score: 0.849620\n",
      "Iteration 126, loss = 0.32974735\n",
      "Validation score: 0.849483\n",
      "Iteration 127, loss = 0.32975116\n",
      "Validation score: 0.849630\n",
      "Iteration 128, loss = 0.32973755\n",
      "Validation score: 0.849980\n",
      "Iteration 129, loss = 0.32972585\n",
      "Validation score: 0.849336\n",
      "Iteration 130, loss = 0.32973217\n",
      "Validation score: 0.849448\n",
      "Iteration 131, loss = 0.32971779\n",
      "Validation score: 0.849884\n",
      "Iteration 132, loss = 0.32970960\n",
      "Validation score: 0.849316\n",
      "Iteration 133, loss = 0.32969814\n",
      "Validation score: 0.849620\n",
      "Iteration 134, loss = 0.32970009\n",
      "Validation score: 0.849437\n",
      "Iteration 135, loss = 0.32968365\n",
      "Validation score: 0.849706\n",
      "Iteration 136, loss = 0.32967804\n",
      "Validation score: 0.849493\n",
      "Iteration 137, loss = 0.32966555\n",
      "Validation score: 0.849777\n",
      "Iteration 138, loss = 0.32967301\n",
      "Validation score: 0.849427\n",
      "Iteration 139, loss = 0.32965537\n",
      "Validation score: 0.849564\n",
      "Iteration 140, loss = 0.32965093\n",
      "Validation score: 0.849519\n",
      "Iteration 141, loss = 0.32964475\n",
      "Validation score: 0.849620\n",
      "Iteration 142, loss = 0.32962790\n",
      "Validation score: 0.849904\n",
      "Iteration 143, loss = 0.32962828\n",
      "Validation score: 0.849432\n",
      "Iteration 144, loss = 0.32960971\n",
      "Validation score: 0.849534\n",
      "Iteration 145, loss = 0.32961373\n",
      "Validation score: 0.849686\n",
      "Iteration 146, loss = 0.32960184\n",
      "Validation score: 0.849610\n",
      "Iteration 147, loss = 0.32961299\n",
      "Validation score: 0.849823\n",
      "Iteration 148, loss = 0.32960315\n",
      "Validation score: 0.849706\n",
      "Iteration 149, loss = 0.32959763\n",
      "Validation score: 0.849650\n",
      "Iteration 150, loss = 0.32958836\n",
      "Validation score: 0.849686\n",
      "Iteration 151, loss = 0.32956885\n",
      "Validation score: 0.849843\n",
      "Iteration 152, loss = 0.32957526\n",
      "Validation score: 0.849600\n",
      "Iteration 153, loss = 0.32956657\n",
      "Validation score: 0.849615\n",
      "Iteration 154, loss = 0.32956008\n",
      "Validation score: 0.849747\n",
      "Iteration 155, loss = 0.32953864\n",
      "Validation score: 0.849757\n",
      "Iteration 156, loss = 0.32954251\n",
      "Validation score: 0.849610\n",
      "Iteration 157, loss = 0.32953196\n",
      "Validation score: 0.849285\n",
      "Iteration 158, loss = 0.32953127\n",
      "Validation score: 0.849980\n",
      "Iteration 159, loss = 0.32950756\n",
      "Validation score: 0.849833\n",
      "Iteration 160, loss = 0.32951751\n",
      "Validation score: 0.849894\n",
      "Iteration 161, loss = 0.32950881\n",
      "Validation score: 0.849924\n",
      "Iteration 162, loss = 0.32949561\n",
      "Validation score: 0.849808\n",
      "Iteration 163, loss = 0.32949110\n",
      "Validation score: 0.849732\n",
      "Iteration 164, loss = 0.32949217\n",
      "Validation score: 0.849843\n",
      "Iteration 165, loss = 0.32948355\n",
      "Validation score: 0.849813\n",
      "Iteration 166, loss = 0.32946907\n",
      "Validation score: 0.849802\n",
      "Iteration 167, loss = 0.32947922\n",
      "Validation score: 0.849808\n",
      "Iteration 168, loss = 0.32946898\n",
      "Validation score: 0.849590\n",
      "Iteration 169, loss = 0.32946381\n",
      "Validation score: 0.849965\n",
      "Iteration 170, loss = 0.32945654\n",
      "Validation score: 0.849752\n",
      "Iteration 171, loss = 0.32944551\n",
      "Validation score: 0.849894\n",
      "Iteration 172, loss = 0.32943610\n",
      "Validation score: 0.849802\n",
      "Iteration 173, loss = 0.32945004\n",
      "Validation score: 0.849934\n",
      "Iteration 174, loss = 0.32942012\n",
      "Validation score: 0.849838\n",
      "Iteration 175, loss = 0.32942903\n",
      "Validation score: 0.849879\n",
      "Iteration 176, loss = 0.32942146\n",
      "Validation score: 0.849889\n",
      "Iteration 177, loss = 0.32940434\n",
      "Validation score: 0.849970\n",
      "Iteration 178, loss = 0.32940687\n",
      "Validation score: 0.849808\n",
      "Iteration 179, loss = 0.32939195\n",
      "Validation score: 0.849818\n",
      "Iteration 180, loss = 0.32938162\n",
      "Validation score: 0.849726\n",
      "Iteration 181, loss = 0.32938609\n",
      "Validation score: 0.850173\n",
      "Iteration 182, loss = 0.32938541\n",
      "Validation score: 0.849960\n",
      "Iteration 183, loss = 0.32936784\n",
      "Validation score: 0.850157\n",
      "Iteration 184, loss = 0.32936829\n",
      "Validation score: 0.849737\n",
      "Iteration 185, loss = 0.32935815\n",
      "Validation score: 0.849894\n",
      "Iteration 186, loss = 0.32934539\n",
      "Validation score: 0.849853\n",
      "Iteration 187, loss = 0.32934882\n",
      "Validation score: 0.849544\n",
      "Iteration 188, loss = 0.32933840\n",
      "Validation score: 0.849544\n",
      "Iteration 189, loss = 0.32932441\n",
      "Validation score: 0.849884\n",
      "Iteration 190, loss = 0.32933844\n",
      "Validation score: 0.849868\n",
      "Iteration 191, loss = 0.32931673\n",
      "Validation score: 0.849975\n",
      "Iteration 192, loss = 0.32932211\n",
      "Validation score: 0.849970\n",
      "Iteration 193, loss = 0.32930603\n",
      "Validation score: 0.850183\n",
      "Iteration 194, loss = 0.32930561\n",
      "Validation score: 0.849706\n",
      "Iteration 195, loss = 0.32930273\n",
      "Validation score: 0.849757\n",
      "Iteration 196, loss = 0.32928876\n",
      "Validation score: 0.849666\n",
      "Iteration 197, loss = 0.32928347\n",
      "Validation score: 0.849650\n",
      "Iteration 198, loss = 0.32927759\n",
      "Validation score: 0.849767\n",
      "Iteration 199, loss = 0.32927142\n",
      "Validation score: 0.849503\n",
      "Iteration 200, loss = 0.32927371\n",
      "Validation score: 0.849524\n",
      "Iteration 201, loss = 0.32924996\n",
      "Validation score: 0.850041\n",
      "Iteration 202, loss = 0.32924859\n",
      "Validation score: 0.849250\n",
      "Iteration 203, loss = 0.32924680\n",
      "Validation score: 0.849645\n",
      "Iteration 204, loss = 0.32925679\n",
      "Validation score: 0.849732\n",
      "Iteration 205, loss = 0.32923565\n",
      "Validation score: 0.849823\n",
      "Iteration 206, loss = 0.32922956\n",
      "Validation score: 0.849681\n",
      "Iteration 207, loss = 0.32921205\n",
      "Validation score: 0.849610\n",
      "Iteration 208, loss = 0.32921322\n",
      "Validation score: 0.849792\n",
      "Iteration 209, loss = 0.32920054\n",
      "Validation score: 0.849696\n",
      "Iteration 210, loss = 0.32920527\n",
      "Validation score: 0.849732\n",
      "Iteration 211, loss = 0.32920320\n",
      "Validation score: 0.849600\n",
      "Iteration 212, loss = 0.32919254\n",
      "Validation score: 0.849655\n",
      "Iteration 213, loss = 0.32918835\n",
      "Validation score: 0.849645\n",
      "Iteration 214, loss = 0.32916284\n",
      "Validation score: 0.849787\n",
      "Iteration 215, loss = 0.32917761\n",
      "Validation score: 0.849762\n",
      "Iteration 216, loss = 0.32916188\n",
      "Validation score: 0.849625\n",
      "Iteration 217, loss = 0.32914531\n",
      "Validation score: 0.849671\n",
      "Iteration 218, loss = 0.32914056\n",
      "Validation score: 0.849863\n",
      "Iteration 219, loss = 0.32913431\n",
      "Validation score: 0.849909\n",
      "Validation score did not improve more than tol=0.000100 for 200 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'make_scorer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 66\u001b[0m\n\u001b[1;32m     57\u001b[0m         scores \u001b[38;5;241m=\u001b[39m cross_validate(mlp_model, X_train_scaled, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mscoring, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m         cv_results[name] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     60\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_recall\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m     61\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_recall\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_time\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),  \u001b[38;5;66;03m# Optional: Track training time\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         }\n\u001b[0;32m---> 66\u001b[0m \u001b[43mmlp_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpq_jar\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[46], line 56\u001b[0m, in \u001b[0;36mmlp_baseline\u001b[0;34m(lazy_dict)\u001b[0m\n\u001b[1;32m     54\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(mlp_model, file)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Cross-Validation and Evaluation\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m scoring \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmake_scorer\u001b[49m(recall_score)}\n\u001b[1;32m     57\u001b[0m scores \u001b[38;5;241m=\u001b[39m cross_validate(mlp_model, X_train_scaled, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mscoring, return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m cv_results[name] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_recall\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_recall\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_time\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(),  \u001b[38;5;66;03m# Optional: Track training time\u001b[39;00m\n\u001b[1;32m     63\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_scorer' is not defined"
     ]
    }
   ],
   "source": [
    "def mlp_baseline(lazy_dict):\n",
    "    baseline_results = dict()\n",
    "    # Initialize MLP parameters\n",
    "    params = {'activation':'tanh', 'solver':'adam', 'valid_frac':0.2,\n",
    "      'alpha':0.001, 'learn_rate_init':0.0001,\n",
    "      'max_iter':1000, 'n_iter_no_change':200,\n",
    "      'rand_state': 3}\n",
    "    \n",
    "    # MLP for each Dataframe\n",
    "    for name in unq_names:\n",
    "        # pl.LazyFrame Names\n",
    "        X_train_name = f\"{name}_X_train\"\n",
    "        y_train_name = f\"{name}_y_train\"\n",
    "        (X_test_name, y_test_name) = corr_testset(name)\n",
    "        \n",
    "        # Collect pl.LazyFrame and convert to pd.DataFrame\n",
    "        X_train = lazy_dict[X_train_name].collect().to_pandas()\n",
    "        y_train = lazy_dict[y_train_name].collect().to_pandas()\n",
    "        X_test = lazy_dict[X_test_name].collect().to_pandas()\n",
    "        y_test = lazy_dict[y_test_name].collect().to_pandas()\n",
    "        \n",
    "        # Remove index column\n",
    "        if \"__index_level_0__\" in X_train.columns:\n",
    "            X_train = X_train.drop(columns=['__index_level_0__'])\n",
    "        if \"__index_level_0__\" in y_train.columns:\n",
    "            y_train = y_train.drop(columns=['__index_level_0__'])\n",
    "        if \"__index_level_0__\" in X_test.columns:\n",
    "            X_test = X_test.drop(columns=['__index_level_0__'])\n",
    "        if \"__index_level_0__\" in y_test.columns:\n",
    "            y_test = y_test.drop(columns=['__index_level_0__'])\n",
    "            \n",
    "        # Standardize X_train and X_test by the standardization scalar of X_train\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        print(\"checkpoint - Standardized\")\n",
    "        \n",
    "        # Initialize mlp model\n",
    "        mlp_model = mlp(\n",
    "            hidden_layer_sizes=([8,4,8]),\n",
    "            validation_fraction = params['valid_frac'],\n",
    "            activation = params['activation'],\n",
    "            solver = params['solver'],\n",
    "            alpha = params['alpha'],\n",
    "            learning_rate = \"adaptive\",\n",
    "            learning_rate_init = params['learn_rate_init'],\n",
    "            batch_size = \"auto\",\n",
    "            max_iter = params['max_iter'],\n",
    "            early_stopping = True,\n",
    "            n_iter_no_change = params['n_iter_no_change'],\n",
    "            verbose= True,\n",
    "            random_state = params['rand_state'])\n",
    "        \n",
    "        # Train the model\n",
    "        mlp_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Save the Trained model\n",
    "        with open(f\"{save_pth}{name}.pkl\", 'wb') as file:\n",
    "            pickle.dump(mlp_model, file)\n",
    "            \n",
    "        # Cross-Validation and Evaluation\n",
    "        scoring = {'recall': make_scorer(recall_score)}\n",
    "        scores = cross_validate(mlp_model, X_train_scaled, y_train, cv=5, scoring=scoring, return_train_score=True)\n",
    "\n",
    "        # Store results in the dictionary\n",
    "        baseline_results['dataset_name'].append(name)\n",
    "        baseline_results['train_recall'].append(scores['train_recall'].mean())\n",
    "        baseline_results['test_recall'].append(scores['test_recall'].mean())\n",
    "        baseline_results['fit_time'].append(scores['fit_time'].mean())\n",
    "    df_baseline_results = pd.DataFrame(baseline_results)\n",
    "    df_baseline_results.to_parquet(f\"{save_pth}baseline_results.pkl\")\n",
    "    return df_baseline_results\n",
    "\n",
    "mlp_baseline(pq_jar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c122f60-86d6-4fcd-aabe-4af7a113f4c3",
   "metadata": {},
   "source": [
    "## Save as Pickle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "203C",
   "language": "python",
   "name": "203c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
