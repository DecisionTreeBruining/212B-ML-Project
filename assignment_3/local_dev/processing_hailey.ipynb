{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets that Drop the Yes or No Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup\n",
    "\n",
    "Significant functions from [assignment_3_tools.py](./assignment_3_tools.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time # Runtime\n",
    "import pickle # Model Saving\n",
    "import logging # Log Checkpoints\n",
    "import numpy as np # Flatten y vectors\n",
    "import pandas as pd # DataFrame\n",
    "import polars as pl # LazyFrame\n",
    "from sklearn.preprocessing import StandardScaler # X Standardization\n",
    "from sklearn.neural_network import MLPClassifier as mlp # model\n",
    "from sklearn.metrics import recall_score, roc_auc_score, accuracy_score # Scoring\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, ParameterGrid\n",
    "from great_tables import GT, md, html, from_column, style, loc, vals\n",
    "from assignment_3_tools import parquet_to_dict, unq_df_names, corr_testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Datasets and Corresponding Testsets\n",
    "\n",
    "In [preprocess notebook](./taylor_preprocess.ipynb), all of the null-threshold datasets were split into X_train, y_train, X_test, and y_test. The X_train, and y_train sets of each null-threshold datasets were balanced using random over/under sampling. Therefore when `parquet_to_dict()` is called, the dictionary will contain the X_train, y_train, X_test, y_test which correspond to one dataset. To resolve this, `unq_df_names()` and `corr_testset` record the dataset names and corresponding testsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazy_read_parquet(path):\n",
    "    \"\"\"\n",
    "    Lazy read all parquet files in a folder.\n",
    "    ---\n",
    "    Args: \n",
    "        Path: Relative Path to folder\n",
    "    Return: \n",
    "        lazy_frames_dict: Dictionary of lazy dataframes\n",
    "    \"\"\"\n",
    "    lazy_frames_dict = {}\n",
    "    for filename in os.listdir(path): # Iterate over each file\n",
    "        if filename.endswith(\".parquet\"):\n",
    "            file_path = os.path.join(path, filename) # File Path\n",
    "            lazy_frame = pl.scan_parquet(file_path) # Lazy read\n",
    "            key = os.path.splitext(filename)[0] # key = filename\n",
    "            lazy_frames_dict[key] = lazy_frame # Add lazyframe to dictionary\n",
    "    return lazy_frames_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../../Data/GoogleDrive/MLP_Dataset/\"\n",
    "df_dict_all = lazy_read_parquet(root_path)\n",
    "X_test = df_dict_all['Under_Sample_1:1_threshold_20_X_test'].collect().to_pandas()\n",
    "X_train = df_dict_all['Under_Sample_1:1_threshold_20_X_train'].collect().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581178, 121)\n",
      "(109919, 122)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['onehot__State_Alabama', 'onehot__State_Alaska',\n",
       "       'onehot__State_Arizona', 'onehot__State_Arkansas',\n",
       "       'onehot__State_California', 'onehot__State_Colorado',\n",
       "       'onehot__State_Connecticut', 'onehot__State_Delaware',\n",
       "       'onehot__State_District of Columbia', 'onehot__State_Florida',\n",
       "       ...\n",
       "       'LastCheckupTime_label__LastCheckupTime',\n",
       "       'RemovedTeeth_label__RemovedTeeth', 'SmokerStatus_label__SmokerStatus',\n",
       "       'ECigaretteUsage_label__ECigaretteUsage',\n",
       "       'remainder__PhysicalHealthDays', 'remainder__MentalHealthDays',\n",
       "       'remainder__SleepHours', 'remainder__HeightInMeters',\n",
       "       'remainder__WeightInKilograms', '__index_level_0__'],\n",
       "      dtype='object', length=122)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep all the No columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehot__State_Wyoming\n",
      "onehot__Sex_Male\n",
      "onehot__PhysicalActivities_Yes\n",
      "onehot__HadAsthma_Yes\n",
      "onehot__HadSkinCancer_Yes\n",
      "onehot__HadCOPD_Yes\n",
      "onehot__HadDepressiveDisorder_Yes\n",
      "onehot__HadKidneyDisease_Yes\n",
      "onehot__HadArthritis_Yes\n",
      "onehot__HadDiabetes_Yes, but only during pregnancy (female)\n",
      "onehot__DeafOrHardOfHearing_Yes\n",
      "onehot__BlindOrVisionDifficulty_Yes\n",
      "onehot__DifficultyConcentrating_Yes\n",
      "onehot__DifficultyWalking_Yes\n",
      "onehot__DifficultyDressingBathing_Yes\n",
      "onehot__DifficultyErrands_Yes\n",
      "onehot__ChestScan_Yes\n",
      "onehot__RaceEthnicityCategory_White only, Non-Hispanic\n",
      "onehot__AlcoholDrinkers_Yes\n",
      "onehot__HIVTesting_Yes\n",
      "onehot__FluVaxLast12_Yes\n",
      "onehot__PneumoVaxEver_Yes\n",
      "onehot__TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap\n",
      "onehot__HighRiskLastYear_Yes\n",
      "onehot__CovidPos_Yes\n"
     ]
    }
   ],
   "source": [
    "# Parsing the column names to group by the categorical variable\n",
    "groups = {}\n",
    "for column in X_train.columns:\n",
    "    # format 'onehot__<Category>_<Value>'\n",
    "    category = column.split('__')[1].split('_')[0]\n",
    "    if category in groups:\n",
    "        groups[category].append(column)\n",
    "    else:\n",
    "        groups[category] = [column]\n",
    "\n",
    "# Drop the first column from each group\n",
    "for category, columns in groups.items():\n",
    "    # Drop the last column (Yes columns) to reduce sparsity in feature space\n",
    "    if len(columns) != 1:\n",
    "        print(columns[-1])\n",
    "        X_train.drop(columns=columns[-1], inplace=True)\n",
    "        X_test.drop(columns=columns[-1], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581178, 120)\n",
      "(109919, 121)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_No.shape)\n",
    "print(X_test_No.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_parquet(root_path + \"Under_Sample_1:1_threshold_20_X_train_No.parquet\")\n",
    "X_test.to_parquet(root_path + \"Under_Sample_1:1_threshold_20_X_test_No.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep all the Yes columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the column names to group by the categorical variable\n",
    "groups = {}\n",
    "for column in X_train.columns:\n",
    "    # format 'onehot__<Category>_<Value>'\n",
    "    category = column.split('__')[1].split('_')[0]\n",
    "    if category in groups:\n",
    "        groups[category].append(column)\n",
    "    else:\n",
    "        groups[category] = [column]\n",
    "\n",
    "# Drop the first column from each group\n",
    "for category, columns in groups.items():\n",
    "    # Drop the first column (No columns)\n",
    "    if len(columns) != 1:\n",
    "        X_train.drop(columns=columns[0], inplace=True)\n",
    "        X_test.drop(columns=columns[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['onehot__State_Alaska', 'onehot__State_Arizona',\n",
       "       'onehot__State_Arkansas', 'onehot__State_California',\n",
       "       'onehot__State_Colorado', 'onehot__State_Connecticut',\n",
       "       'onehot__State_Delaware', 'onehot__State_District of Columbia',\n",
       "       'onehot__State_Florida', 'onehot__State_Georgia', 'onehot__State_Guam',\n",
       "       'onehot__State_Hawaii', 'onehot__State_Idaho', 'onehot__State_Illinois',\n",
       "       'onehot__State_Indiana', 'onehot__State_Iowa', 'onehot__State_Kansas',\n",
       "       'onehot__State_Kentucky', 'onehot__State_Louisiana',\n",
       "       'onehot__State_Maine', 'onehot__State_Maryland',\n",
       "       'onehot__State_Massachusetts', 'onehot__State_Michigan',\n",
       "       'onehot__State_Minnesota', 'onehot__State_Mississippi',\n",
       "       'onehot__State_Missouri', 'onehot__State_Montana',\n",
       "       'onehot__State_Nebraska', 'onehot__State_Nevada',\n",
       "       'onehot__State_New Hampshire', 'onehot__State_New Jersey',\n",
       "       'onehot__State_New Mexico', 'onehot__State_New York',\n",
       "       'onehot__State_North Carolina', 'onehot__State_North Dakota',\n",
       "       'onehot__State_Ohio', 'onehot__State_Oklahoma', 'onehot__State_Oregon',\n",
       "       'onehot__State_Pennsylvania', 'onehot__State_Puerto Rico',\n",
       "       'onehot__State_Rhode Island', 'onehot__State_South Carolina',\n",
       "       'onehot__State_South Dakota', 'onehot__State_Tennessee',\n",
       "       'onehot__State_Texas', 'onehot__State_Utah', 'onehot__State_Vermont',\n",
       "       'onehot__State_Virgin Islands', 'onehot__State_Virginia',\n",
       "       'onehot__State_Washington', 'onehot__State_West Virginia',\n",
       "       'onehot__State_Wisconsin', 'onehot__State_Wyoming', 'onehot__Sex_Male',\n",
       "       'onehot__PhysicalActivities_Yes', 'onehot__HadAsthma_Yes',\n",
       "       'onehot__HadSkinCancer_Yes', 'onehot__HadCOPD_Yes',\n",
       "       'onehot__HadDepressiveDisorder_Yes', 'onehot__HadKidneyDisease_Yes',\n",
       "       'onehot__HadArthritis_Yes',\n",
       "       'onehot__HadDiabetes_No, pre-diabetes or borderline diabetes',\n",
       "       'onehot__HadDiabetes_Yes',\n",
       "       'onehot__HadDiabetes_Yes, but only during pregnancy (female)',\n",
       "       'onehot__DeafOrHardOfHearing_Yes',\n",
       "       'onehot__BlindOrVisionDifficulty_Yes',\n",
       "       'onehot__DifficultyConcentrating_Yes', 'onehot__DifficultyWalking_Yes',\n",
       "       'onehot__DifficultyDressingBathing_Yes',\n",
       "       'onehot__DifficultyErrands_Yes', 'onehot__ChestScan_Yes',\n",
       "       'onehot__RaceEthnicityCategory_Hispanic',\n",
       "       'onehot__RaceEthnicityCategory_Multiracial, Non-Hispanic',\n",
       "       'onehot__RaceEthnicityCategory_Other race only, Non-Hispanic',\n",
       "       'onehot__RaceEthnicityCategory_White only, Non-Hispanic',\n",
       "       'onehot__AlcoholDrinkers_Yes', 'onehot__HIVTesting_Yes',\n",
       "       'onehot__FluVaxLast12_Yes', 'onehot__PneumoVaxEver_Yes',\n",
       "       'onehot__TetanusLast10Tdap_Yes, received Tdap',\n",
       "       'onehot__TetanusLast10Tdap_Yes, received tetanus shot but not sure what type',\n",
       "       'onehot__TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap',\n",
       "       'onehot__HighRiskLastYear_Yes',\n",
       "       'onehot__CovidPos_Tested positive using home test without a health professional',\n",
       "       'onehot__CovidPos_Yes', 'label__AgeCategory',\n",
       "       'GeneralHealth_label__GeneralHealth',\n",
       "       'LastCheckupTime_label__LastCheckupTime',\n",
       "       'RemovedTeeth_label__RemovedTeeth', 'SmokerStatus_label__SmokerStatus',\n",
       "       'ECigaretteUsage_label__ECigaretteUsage',\n",
       "       'remainder__PhysicalHealthDays', 'remainder__MentalHealthDays',\n",
       "       'remainder__SleepHours', 'remainder__HeightInMeters',\n",
       "       'remainder__WeightInKilograms'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_parquet(root_path + \"Under_Sample_1:1_threshold_20_X_train_Yes.parquet\")\n",
    "X_test.to_parquet(root_path + \"Under_Sample_1:1_threshold_20_X_test_Yes.parquet\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
